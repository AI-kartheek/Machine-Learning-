{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we performed Model selection and Hyper parameter tuning on **Diabetes after feature Engineering** dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.330737</td>\n",
       "      <td>6.205037</td>\n",
       "      <td>36.329902</td>\n",
       "      <td>27.149304</td>\n",
       "      <td>20.023718</td>\n",
       "      <td>5.605497</td>\n",
       "      <td>0.310087</td>\n",
       "      <td>0.870964</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.738299</td>\n",
       "      <td>5.390749</td>\n",
       "      <td>33.865339</td>\n",
       "      <td>22.854380</td>\n",
       "      <td>11.929581</td>\n",
       "      <td>5.087564</td>\n",
       "      <td>0.225562</td>\n",
       "      <td>0.863878</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.695814</td>\n",
       "      <td>6.527653</td>\n",
       "      <td>33.033688</td>\n",
       "      <td>22.854380</td>\n",
       "      <td>20.067285</td>\n",
       "      <td>4.808004</td>\n",
       "      <td>0.320037</td>\n",
       "      <td>0.864470</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.738299</td>\n",
       "      <td>5.456704</td>\n",
       "      <td>33.865339</td>\n",
       "      <td>18.475901</td>\n",
       "      <td>13.590624</td>\n",
       "      <td>5.206304</td>\n",
       "      <td>0.132705</td>\n",
       "      <td>0.854735</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.089163</td>\n",
       "      <td>22.561724</td>\n",
       "      <td>27.149304</td>\n",
       "      <td>17.924559</td>\n",
       "      <td>6.193787</td>\n",
       "      <td>0.394806</td>\n",
       "      <td>0.865025</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies   Glucose  BloodPressure  SkinThickness    Insulin       BMI  \\\n",
       "0     2.330737  6.205037      36.329902      27.149304  20.023718  5.605497   \n",
       "1     0.738299  5.390749      33.865339      22.854380  11.929581  5.087564   \n",
       "2     2.695814  6.527653      33.033688      22.854380  20.067285  4.808004   \n",
       "3     0.738299  5.456704      33.865339      18.475901  13.590624  5.206304   \n",
       "4     0.000000  6.089163      22.561724      27.149304  17.924559  6.193787   \n",
       "\n",
       "   DiabetesPedigreeFunction       Age  Outcome  \n",
       "0                  0.310087  0.870964        1  \n",
       "1                  0.225562  0.863878        0  \n",
       "2                  0.320037  0.864470        1  \n",
       "3                  0.132705  0.854735        0  \n",
       "4                  0.394806  0.865025        1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "data = pd.read_csv('datasets/Diabetes After Feature Engineering.csv')\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((614, 8), (154, 8))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.drop('Outcome', axis= 1)\n",
    "Y = data['Outcome']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size = 0.2, random_state = 0)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>2.522655</td>\n",
       "      <td>6.225257</td>\n",
       "      <td>38.752350</td>\n",
       "      <td>22.854380</td>\n",
       "      <td>15.645104</td>\n",
       "      <td>5.712516</td>\n",
       "      <td>0.324205</td>\n",
       "      <td>0.871799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>1.867137</td>\n",
       "      <td>5.580920</td>\n",
       "      <td>31.354045</td>\n",
       "      <td>18.475901</td>\n",
       "      <td>12.866988</td>\n",
       "      <td>5.214054</td>\n",
       "      <td>0.259198</td>\n",
       "      <td>0.856033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.369532</td>\n",
       "      <td>43.485684</td>\n",
       "      <td>25.725884</td>\n",
       "      <td>24.556112</td>\n",
       "      <td>6.575816</td>\n",
       "      <td>0.253814</td>\n",
       "      <td>0.857217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.738299</td>\n",
       "      <td>5.750825</td>\n",
       "      <td>29.651155</td>\n",
       "      <td>16.994122</td>\n",
       "      <td>16.166911</td>\n",
       "      <td>4.972240</td>\n",
       "      <td>0.349805</td>\n",
       "      <td>0.857217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>2.695814</td>\n",
       "      <td>5.892249</td>\n",
       "      <td>37.546134</td>\n",
       "      <td>24.294427</td>\n",
       "      <td>17.046939</td>\n",
       "      <td>5.350220</td>\n",
       "      <td>0.142543</td>\n",
       "      <td>0.867347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies   Glucose  BloodPressure  SkinThickness    Insulin       BMI  \\\n",
       "603     2.522655  6.225257      38.752350      22.854380  15.645104  5.712516   \n",
       "118     1.867137  5.580920      31.354045      18.475901  12.866988  5.214054   \n",
       "247     0.000000  6.369532      43.485684      25.725884  24.556112  6.575816   \n",
       "157     0.738299  5.750825      29.651155      16.994122  16.166911  4.972240   \n",
       "468     2.695814  5.892249      37.546134      24.294427  17.046939  5.350220   \n",
       "\n",
       "     DiabetesPedigreeFunction       Age  \n",
       "603                  0.324205  0.871799  \n",
       "118                  0.259198  0.856033  \n",
       "247                  0.253814  0.857217  \n",
       "157                  0.349805  0.857217  \n",
       "468                  0.142543  0.867347  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "import xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC_Model = RandomForestClassifier(random_state=0, n_jobs= -1)\n",
    "GBC_Model = GradientBoostingClassifier(random_state=0)\n",
    "ABC_Model = AdaBoostClassifier(random_state=0, n_estimators=100)\n",
    "DTC_Model = DecisionTreeClassifier(random_state=0)\n",
    "LoR_Model = LogisticRegression(random_state=0, n_jobs=-1)\n",
    "KNN_Model = KNeighborsClassifier(n_jobs=-1, n_neighbors = 5)\n",
    "GNB_Model = GaussianNB()\n",
    "SVM_Model = svm.SVC(random_state=0)\n",
    "XGB_Model = xgboost.XGBClassifier(random_state=0, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Models = (RFC_Model, GBC_Model, ABC_Model, DTC_Model, LoR_Model, KNN_Model, GNB_Model, SVM_Model, XGB_Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Model RandomForestClassifier(n_jobs=-1, random_state=0)\n",
      "Recall Score = 0.6007575757575757\n",
      "\n",
      "For Model GradientBoostingClassifier(random_state=0)\n",
      "Recall Score = 0.6307239057239057\n",
      "\n",
      "For Model AdaBoostClassifier(n_estimators=100, random_state=0)\n",
      "Recall Score = 0.5974747474747474\n",
      "\n",
      "For Model DecisionTreeClassifier(random_state=0)\n",
      "Recall Score = 0.5936026936026936\n",
      "\n",
      "For Model LogisticRegression(n_jobs=-1, random_state=0)\n",
      "Recall Score = 0.5672558922558922\n",
      "\n",
      "For Model KNeighborsClassifier(n_jobs=-1)\n",
      "Recall Score = 0.49284511784511786\n",
      "\n",
      "For Model GaussianNB()\n",
      "Recall Score = 0.7053872053872055\n",
      "\n",
      "For Model SVC(random_state=0)\n",
      "Recall Score = 0.41397306397306394\n",
      "\n",
      "For Model XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
      "              gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n",
      "              random_state=0, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None)\n",
      "Recall Score = 0.6047138047138046\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Selected_Models = []\n",
    "scores =[]\n",
    "for model in Models:\n",
    "    print(\"For Model {}\".format(model))\n",
    "    score = cross_val_score(model, X, Y, cv=6, scoring = 'recall').mean()\n",
    "    print(\"Recall Score = {}\".format(score))\n",
    "    if(score > 0.6):\n",
    "        Selected_Models.append(model)\n",
    "        scores.append(score)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6007575757575757 =========> RandomForestClassifier(n_jobs=-1, random_state=0)\n",
      "\n",
      "0.6307239057239057 =========> GradientBoostingClassifier(random_state=0)\n",
      "\n",
      "0.7053872053872055 =========> GaussianNB()\n",
      "\n",
      "0.6047138047138046 =========> XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
      "              gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n",
      "              random_state=0, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#these are selected models to imporove score by hyper parameter tuning\n",
    "for model, score in zip(Selected_Models, scores):\n",
    "    print(f\"{score} =========> {str(model)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``Gausian Naive Bayes`` performs ``best`` on our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameter optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a) for Naive Bayes**\n",
    "\n",
    "**Grid Search Cv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    0.7s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, estimator=GaussianNB(), n_jobs=-1,\n",
       "             param_grid={'var_smoothing': [1e-06, 1e-07, 1e-08, 1e-09, 1e-10]},\n",
       "             scoring='recall', verbose=2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smoothing = [1e-06,1e-07, 1e-08, 1e-09, 1e-10]\n",
    "random_grid = {'var_smoothing' : smoothing}\n",
    "grid_search = GridSearchCV(estimator= GNB_Model, param_grid= random_grid, cv =2 , n_jobs = -1, scoring='recall' ,verbose=2)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(var_smoothing=1e-08)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_grid=grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[86 21]\n",
      " [11 36]]\n",
      "Recall Score 0.7659574468085106\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.80      0.84       107\n",
      "           1       0.63      0.77      0.69        47\n",
      "\n",
      "    accuracy                           0.79       154\n",
      "   macro avg       0.76      0.78      0.77       154\n",
      "weighted avg       0.81      0.79      0.80       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred=best_grid.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(\"Recall Score {}\\n\".format(recall_score(y_test,y_pred)))\n",
    "print(\"Classification report:\\n {}\".format(classification_report(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) for XGboost**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First find the bset n_estimators for an xg_boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_recalls = dict()\n",
    "for i in range(2, 30):\n",
    "    xgb = xgboost.XGBClassifier(n_estimators = i, n_jobs = -1, random_state = 0)\n",
    "    xgb.fit(X_train, y_train)\n",
    "    y_pred = xgb.predict(X_test)\n",
    "    score = recall_score(y_test, y_pred)\n",
    "    n_recalls.update({i:score})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_recalls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "uncommon out to see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_estimators = 17, Recall Score = 0.723404255319149\n"
     ]
    }
   ],
   "source": [
    "for i in range(2, 30):\n",
    "    if(n_recalls[i] == max(n_recalls.values())):\n",
    "        print(\"For n_estimators = {}, Recall Score = {}\". format(i, n_recalls[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so we have to use ``n_estiamtors = 15-18`` for better performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Range of Max Depth for n_estimators = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "MaxDepth_recalls = dict()\n",
    "for i in range(2, 30):\n",
    "    xgb = xgboost.XGBClassifier(n_estimators = 17,max_depth = i, n_jobs = -1, random_state = 0)\n",
    "    xgb.fit(X_train, y_train)\n",
    "    y_pred = xgb.predict(X_test)\n",
    "    score = recall_score(y_test, y_pred)\n",
    "    MaxDepth_recalls.update({i:score})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MaxDepth_recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Range of Max Depth for n_estimators = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "MaxDepth_recalls_1 = dict()\n",
    "for i in range(2, 30):\n",
    "    xgb = xgboost.XGBClassifier(n_estimators = 16,max_depth = i, n_jobs = -1, random_state = 0)\n",
    "    xgb.fit(X_train, y_train)\n",
    "    y_pred = xgb.predict(X_test)\n",
    "    score = recall_score(y_test, y_pred)\n",
    "    MaxDepth_recalls_1.update({i:score})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MaxDepth_recalls_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above it is obvious that ``max_Depth`` is constant for ``[3, 5, 6, 7, 8]``, also performs better on our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lets computer for reg_lambda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_lambda_1 = dict()\n",
    "for i in np.linspace(0, 1):\n",
    "    xgb = xgboost.XGBClassifier(n_estimators = 16, max_depth = 3, reg_lambda=i, n_jobs = -1, random_state = 0)\n",
    "    xgb.fit(X_train, y_train)\n",
    "    y_pred = xgb.predict(X_test)\n",
    "    score = recall_score(y_test, y_pred)\n",
    "    reg_lambda_1.update({i:score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reg_lambda_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For reg_lambda = 0.5714285714285714, Recall Score = 0.7659574468085106\n"
     ]
    }
   ],
   "source": [
    "for i in np.linspace(0,1):\n",
    "    if(reg_lambda_1[i] == max(reg_lambda_1.values())):\n",
    "        print(\"For reg_lambda = {}, Recall Score = {}\". format(i, reg_lambda_1[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so our parameters are ``reg_lambda=0.5789473684210527``, ``max_depth = 3``, ``n_estimators= 16``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=16, n_jobs=-1, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=0.5789473684210527, scale_pos_weight=1,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = xgboost.XGBClassifier(n_estimators = 16,max_depth = 3, reg_lambda=0.5789473684210527, n_jobs = -1, random_state = 0)\n",
    "#recall score = 0.76\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[94 13]\n",
      " [11 36]]\n",
      "Recall Score 0.7659574468085106\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89       107\n",
      "           1       0.73      0.77      0.75        47\n",
      "\n",
      "    accuracy                           0.84       154\n",
      "   macro avg       0.81      0.82      0.82       154\n",
      "weighted avg       0.85      0.84      0.85       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = xgb.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(\"Recall Score {}\".format(recall_score(y_test,y_pred)))\n",
    "print(\"Classification report: \\n{}\".format(classification_report(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c) for GradientBoostingClassifier**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = dict()\n",
    "for i in range(30, 100):\n",
    "    GBC = GradientBoostingClassifier(n_estimators =i, random_state = 0)\n",
    "    GBC.fit(X_train, y_train)\n",
    "    y_pred = GBC.predict(X_test)\n",
    "    score = recall_score(y_test, y_pred)\n",
    "    n_estimators.update({i:score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "selected **n_estimators = [ 52, 60]**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for n_estimators=52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Max_depth_1 = dict()\n",
    "for i in range(1, 20):\n",
    "    GBC = GradientBoostingClassifier(n_estimators =52, max_depth=i, random_state = 0)\n",
    "    GBC.fit(X_train, y_train)\n",
    "    y_pred = GBC.predict(X_test)\n",
    "    score = recall_score(y_test, y_pred)\n",
    "    Max_depth_1.update({i:score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Max_depth_1       # 3 is selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "For n_estimators = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Max_depth_2 = dict()\n",
    "for i in range(1, 20):\n",
    "    GBC = GradientBoostingClassifier(n_estimators =60, max_depth=i, random_state = 0)\n",
    "    GBC.fit(X_train, y_train)\n",
    "    y_pred = GBC.predict(X_test)\n",
    "    score = recall_score(y_test, y_pred)\n",
    "    Max_depth_2.update({i:score})                                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Max_depth_2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence ``n_estimators =[60, 52]`` and ``max_depth=3`` is selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_1 = dict()\n",
    "for i in np.linspace(0.1, 1):\n",
    "    GBC = GradientBoostingClassifier(n_estimators =52,learning_rate=i, max_depth=3, random_state = 0)\n",
    "    GBC.fit(X_train, y_train)\n",
    "    y_pred = GBC.predict(X_test)\n",
    "    score = recall_score(y_test, y_pred)\n",
    "    learning_rate_1.update({i:score})                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning_rate_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_2 = dict()\n",
    "for i in np.linspace(0.1, 1):\n",
    "    GBC = GradientBoostingClassifier(n_estimators =60, learning_rate=i, max_depth=3, random_state = 0)\n",
    "    GBC.fit(X_train, y_train)\n",
    "    y_pred = GBC.predict(X_test)\n",
    "    score = recall_score(y_test, y_pred)\n",
    "    learning_rate_2.update({i:score})                                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning_rate_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``learning_rate=[0.5224489795918368, 0.5040816326530613]``, ``n_estimators= 60``, ``max_depth=3`` is selected, Hence got an recall score of **0.78 and 0.74**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=0.5224489795918368, n_estimators=60,\n",
       "                           random_state=0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBC = GradientBoostingClassifier(n_estimators =60, learning_rate= 0.5224489795918368, max_depth=3, random_state = 0)\n",
    "GBC.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[89 18]\n",
      " [10 37]]\n",
      "Recall Score: 0.7872340425531915\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.83      0.86       107\n",
      "           1       0.67      0.79      0.73        47\n",
      "\n",
      "    accuracy                           0.82       154\n",
      "   macro avg       0.79      0.81      0.79       154\n",
      "weighted avg       0.83      0.82      0.82       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = GBC.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(\"Recall Score: {}\".format(recall_score(y_test,y_pred)))\n",
    "print(\"Classification report: \\n{}\".format(classification_report(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d) for Random Forest Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators_1 = dict()\n",
    "for i in range(1, 30):\n",
    "    RFC = RandomForestClassifier(n_estimators =i,n_jobs=-1, random_state = 0)\n",
    "    RFC.fit(X_train, y_train)\n",
    "    y_pred = RFC.predict(X_test)\n",
    "    score = recall_score(y_test, y_pred)\n",
    "    n_estimators_1.update({i:score})\n",
    "                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.723404255319149"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(n_estimators_1.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_estimators_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Better Results ``n_estimators = [3, 5, 7]``"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for n_estimators = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_max_depth = dict()\n",
    "for i in range(1, 30):\n",
    "    RFC = RandomForestClassifier(n_estimators =3, max_depth= i,n_jobs=-1, random_state = 0)\n",
    "    RFC.fit(X_train, y_train)\n",
    "    y_pred = RFC.predict(X_test)\n",
    "    score = recall_score(y_test, y_pred)\n",
    "    n_max_depth.update({i:score})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.723404255319149"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(n_max_depth.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for n_estimators = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_max_depth_1 = dict()\n",
    "for i in range(1, 30):\n",
    "    RFC = RandomForestClassifier(n_estimators =7, max_depth= i,n_jobs=-1, random_state = 0)\n",
    "    RFC.fit(X_train, y_train)\n",
    "    y_pred = RFC.predict(X_test)\n",
    "    score = recall_score(y_test, y_pred)\n",
    "    n_max_depth_1.update({i:score})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7446808510638298"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(n_max_depth_1.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_max_depth_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_estimators = 7, max_depth = 11, Recall Score = 0.7446808510638298\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 30):\n",
    "    if(n_max_depth_1[i] == max(n_max_depth_1.values())):\n",
    "        print(\"For n_estimators = 7, max_depth = {}, Recall Score = {}\". format(i, n_max_depth_1[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we conclude that ``n_estimators =[3, 7]`` and ``max_depth = [11, 5, 16]``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample_split = dict()\n",
    "for i in range(2, 20):\n",
    "    RFC = RandomForestClassifier(n_estimators =7, min_samples_split= i, max_depth= 11,n_jobs=-1, random_state = 0)\n",
    "    RFC.fit(X_train, y_train)\n",
    "    y_pred = RFC.predict(X_test)\n",
    "    score = recall_score(y_test, y_pred)\n",
    "    n_sample_split.update({i:score})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_sample_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_impurity_dec = dict()\n",
    "for i in [0, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7]:\n",
    "    RFC = RandomForestClassifier(n_estimators =7, min_samples_split= 9, min_impurity_decrease= i,\n",
    "                                 max_depth= 11,n_jobs=-1, random_state = 0)\n",
    "    RFC.fit(X_train, y_train)\n",
    "    y_pred = RFC.predict(X_test)\n",
    "    score = recall_score(y_test, y_pred)\n",
    "    n_impurity_dec.update({i:score})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_impurity_dec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so ``min_sample_split = [2, 7, 9]``, ``n_estimators= 7``, ``max_depth=11``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grid Search CV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = [11, 5, 16]\n",
    "n_estimators =[3, 7]\n",
    "min_sample_split = [2, 7, 9]\n",
    "min_sample_leaf = [2, 1, 7, 9]\n",
    "max_features = ['auto', 'sqrt', 'log2']\n",
    "min_impurity_decrease = [1e-5]\n",
    "class_weight = ['balanced', 'balanced_subsample']\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_gird = {'max_depth': max_depth,\n",
    "              'n_estimators': n_estimators,\n",
    "              'min_samples_split' : min_sample_split,\n",
    "              'min_samples_leaf' : min_sample_leaf,\n",
    "              'max_features' : max_features,\n",
    "              'min_impurity_decrease' : min_impurity_decrease,\n",
    "              'class_weight': class_weight}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 432 candidates, totalling 864 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 504 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 864 out of 864 | elapsed:    4.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, estimator=RandomForestClassifier(n_jobs=-1, random_state=0),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'class_weight': ['balanced', 'balanced_subsample'],\n",
       "                         'max_depth': [11, 5, 16],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'min_impurity_decrease': [1e-05],\n",
       "                         'min_samples_leaf': [2, 1, 7, 9],\n",
       "                         'min_samples_split': [2, 7, 9],\n",
       "                         'n_estimators': [3, 7]},\n",
       "             scoring='recall', verbose=2)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = GridSearchCV(estimator= RFC_Model, param_grid= param_gird, scoring= 'recall', n_jobs= -1, cv= 2, verbose= 2)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': 'balanced_subsample',\n",
       " 'max_depth': 5,\n",
       " 'max_features': 'log2',\n",
       " 'min_impurity_decrease': 1e-05,\n",
       " 'min_samples_leaf': 9,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 7}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[89 18]\n",
      " [ 9 38]]\n",
      "Recall Score 0.8085106382978723\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.83      0.87       107\n",
      "           1       0.68      0.81      0.74        47\n",
      "\n",
      "    accuracy                           0.82       154\n",
      "   macro avg       0.79      0.82      0.80       154\n",
      "weighted avg       0.84      0.82      0.83       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_grid = grid_search.best_estimator_\n",
    "\n",
    "y_pred=best_grid.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(\"Recall Score {}\".format(recall_score(y_test,y_pred)))\n",
    "print(\"Classification report: \\n{}\".format(classification_report(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced_subsample', max_depth=5,\n",
       "                       max_features='log2', min_impurity_decrease=1e-05,\n",
       "                       min_samples_leaf=9, n_estimators=7, n_jobs=-1,\n",
       "                       random_state=0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence As of now ``Random Forest`` Classifer gives the **Highest Recall score**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
